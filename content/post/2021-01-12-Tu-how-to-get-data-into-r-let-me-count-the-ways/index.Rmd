---
title: How to Get Data into R? Let Me Count the Ways...
author: Nathan Brouwer
date: '2021-01-12'
categories:
  - data science
tags:
  - basic R
  - data science
  - learnR
  - R
  - R data structures
  - read.csv
slug: how-to-get-data-into-r-let-me-count-the-ways
math: no
meta: yes
toc: yes
draft: no
excerpt: "Unpacking the many routes to get data into R"
---


<!--more-->

When you start learning R -- or any data analysis software -- one of the biggest challenges is getting data loaded for your analysis.  

Many things contribute to the steepness of the getting-data-into0your-#@@#$%-software learning cuve.  These include

1. You need to understand your computer's **file system**, which is something we rarely teach students, so you can save the file in the proper place 
1. You need to understand how your program interfaces with the file system so you can get it to find where you saved the data.
1. You need to know the precise **file format** your program can take in data.  This is usually **.csv** (**Commas Separated Values**) but there's often some flexiblity in this.  In the case of R data for numeric and character data, .csv is the standard and recommended, but you can also do .xls, .xlsx, interface with Google Sheets, or many other formats.
1. You need to use the proper route/commands to load the data; base R can load .csv on its own, but need an additinal packages to load .xlsx, a different package to interface with Google Sheets, and other packages for each specialized type of data that is out there.
1. The raw data needs to not have any **wonkiness** (yes, a technical term in data science) that will prevent the data from loading properly.  Unfortunately, to parapharase Tolstoy:

> "All data that loads properly is the same; all data that doesn't is wonky in its own way"

One of the reasons I'm developing the [biodata](https://github.com/brouwern/biodata) is to provide easy access to many datasets useful for bilogists and other life scientists learning data science, statistics and bioinformatics.  One feature of this package and its associated website is that many of the data sets are going to be made available in multiple, redundant formats.  

Data in packages is typically stored as a **.RData** file which is either loaded automatically when the package is loaded, or via the data() command.  This makes it super easy and is one of the reasons why I package my teaching and research materials in packages.  This works great - until the package breaks or someone is unable download external software.  The latter is a fairly common problem caused by firewalls or other security settings.  Often these issues can be dealt with on a person's individual computer, but other times require that system admins allow access to the places you want to get things from the internet.  Nothing throws a wrench in a lessons plan like a group of students who can't access the data you neeed.  Because of this, some datasets in [biodata](https://github.com/brouwern/biodata) are built up from scratch by making individuals data points or vectors and putting them together with R's matrix and dataframe-building commands (rbind, cbind, matrix, data.frame).

## Submitting small data sets to the biodata package

The easiest way to submit small dataset to biodata is to create a .R script which builds up the data from individual vectors.  The file should be named something simple like human_gene_lengths_prep.R, where the first part is ideally the name of the R object that will hold the data, and the last part is _prep.R.


Each vector should be the name of the final column in the dataframe.  The nameing conventions I use are below.  

The most important ones are

1. Column names should be short (and MUST be unique within the dataframe).  Shorter names are easier to type, easier to remember, and take up less space on the screen when you do e.g. summary(dataframe).
1. Column names should be descriptive as much as possible
1. If there is a trade-off between short and descriptive, I prefer short.  
1. Use only lower case, even for the first letter.  This prevents the common typo of not hitting the shift key accurately, and makes things consistent
1. Use dots between words if needed, eg. "dry.mass", though I seem to change my mind every few months and use underscores instead ("dry_mass").  Being consistent is the main thing.
1. When shortening names try to use standard abbreviations, eg. "wt" for "weight", "ht" for "height."



Since I've spent far too much of my life doing data entry and currating data sets I have a long list of other, secondary considerations:

1. If there are multiple columns that have the same type of measurement (e.g. weight) for different things, start off with the measurement and put other information next, such as "wt_wet", "wt_dry".  This makes similarities easier to see and is useful when you get to big dataframes and need to use commands such as regular expressions to locate columns.
1. Include **metadata** about what all the columns mean.
1. Don't include units in the column names unless necessary.  For example, if you have weight in grams, and its the only weight varibable in the dataframe, then just call it "wt" and put the fact that its grams in the metadata.  If you happen to have weight in grams and weight in pounds, then use "wt.g" and "wt.lbs"; consider, though, if you only need one of these.


### Exaple dataset

The 8th edition of biochemistry text book by Berg et al (2002) has a table where the 20 cannonical amino acids are listed along with the relative frequeny in three protein secondary structures: alpha helices, beta-pleated sheets, and reverse turns.

The original columns headings and what I abbreviate them to are below.  

1. Amino acid = "aa"
1. Alpha helix = "a.helix"; "alpha.helix" would be ok too becaue the data set it small, but I know want to merge this with a larger dataset.
1. Beta sheet = "b.sheet"; again, "beta.sheet" would be ok because its not too long.
1. Reverse turn = "r.turn"; "reverse.turn" is ok, but is getting long.

The information is key meta data and needs to go EVERYWHERE the data go.

I'll make these vectors like this, including some additional meta data.  When I have time, I like to make the code look pretty by parsing the lines into nice block.  This allows helps me do quality control by allowing me to check if there is the proper number of values.

```{r}
# Amino acid name
## 3-letter aa code
aa <- c("Glu","Ala","Leu","Met","Gln","Lys","Arg","His","Val","Ile",
        "Tyr","Cys","Trp","Phe","Thr","Gly", "Asn","Pro","Ser","Asp")

# Alpha helix
a.helix <- c(1.59,1.41,1.34,1.30,1.27,1.23,1.21,1.05,0.90,1.09,
             0.74,0.66,1.02,1.16,0.76,0.43,0.76,0.34,0.57,0.99)

# Beta sheet
# b.sheet

# Reverse turne
# r.turn

```


Double entry
